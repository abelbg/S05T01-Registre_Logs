{
 "cells": [
  {
   "attachments": {
    "IT%20Logo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IT%20Logo.png](attachment:IT%20Logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><font size=\"5\"><center><b><u>Preparación del Dato en un Proyecto de Machine Learning</u></b></center></font>   \n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\\begin{align*}Alex\\:Kumenius - Business\\hspace{2mm}Intelligence\\hspace{2mm}\\hspace{2mm}Data\\hspace{2mm}Scientist\\end{align*}\n",
    "\n",
    "\\begin{align*}Date : Abril\\hspace{2mm}21^{th}\\hspace{2mm}2021\\end{align*}</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La <span style=color:darkblue><b><u>Preparación del Dato en un Proyecto de Machine Learning</u></b></span> se divide en tres partes:\n",
    "\n",
    "1.- <span style=color:darkgreen>Proceso de aprendizaje automático aplicado</span>   \n",
    "2.- <span style=color:darkgreen>¿Qué es la preparación de datos?</span>   \n",
    "3.- <span style=color:darkgreen>Cómo elegir técnicas de preparación de datos</span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=color:darkgreen>Proceso de Aprendizaje Automático</span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=color:darkred><i>\"… the right features can only be defined in the context of both the model and the data; since data and models are so diverse, it’s difficult to generalize the practice of feature engineering across projects.\"</i></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque tu proyecto es único, los pasos en el camino hacia un buen o incluso el mejor resultado son generalmente los mismos de un proyecto a otro. Esto a veces se denomina \"proceso de aprendizaje automático aplicado\", \"proceso de ciencia de datos\" o el nombre anterior \"descubrimiento de conocimientos en bases de datos -  knowledge discovery in databases\" (KDD).\n",
    "\n",
    "El proceso de aprendizaje automático aplicado consta de una secuencia de pasos. \n",
    "\n",
    "Se inicia el proceso, usando los cuatro pasos de alto nivel:\n",
    "\n",
    "- <b><u>Paso 1:</u></b> <span style=color:blue><b>Definir el problema.</b></span>\n",
    "- <b><u>Paso 2:</u></b> <span style=color:blue><b>preparar los datos.</b></span>\n",
    "- <b><u>Paso 3:</u></b> <span style=color:blue><b>Evaluar modelos.</b></span>\n",
    "- <b><u>Paso 4:</u></b> <span style=color:blue><b>Finalizar modelo.</b></span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><u>Paso 1:</u></b> <span style=color:blue><b>Definir el problema.</b></span>   \n",
    "\n",
    "Este paso tiene que ver con aprender lo suficiente sobre el proyecto para seleccionar el encuadre o encuadres de la tarea de predicción. Por ejemplo, ¿es clasificación o regresión, o algún otro tipo de problema de orden superior?\n",
    "\n",
    "Implica recopilar los datos que se cree que son útiles para hacer una predicción y definir claramente la forma que tomará la predicción. También puede implicar hablar con las partes interesadas del proyecto y otras personas con amplia experiencia en el dominio.\n",
    "\n",
    "Este paso también implica observar de cerca los datos, así como quizás explorar los datos utilizando estadísticas de resumen y visualización de datos.\n",
    "\n",
    "## <b><u>Paso 2:</u></b> <span style=color:blue><b>preparar los datos.</b></span>\n",
    "\n",
    "Este paso se ocupa de transformar los datos sin procesar que se recopilaron en un formulario que se pueda utilizar en el modelado.\n",
    "\n",
    "Las técnicas de pre-procesamiento de datos - <span style=color:blue><b>Data pre-processing</b></span> generalmente se refieren a la <b>adición, eliminación o transformación de dato</b>s del conjunto de entrenamiento -  <span style=color:blue><b>training set data</b></span>.\n",
    "\n",
    "## <b><u>Paso 3:</u></b> <span style=color:blue><b>Evaluar modelos.</b></span>\n",
    "\n",
    "Este paso está relacionado con la evaluación de modelos de aprendizaje automático en su conjunto de datos.\n",
    "\n",
    "Requiere del diseño  de un test de prueba robusto para evaluar sus modelos, de modo que los resultados que obtenga sean confiables y se utilicen para seleccionar entre los modelos que ha evaluado.\n",
    "\n",
    "Esto implica tareas como seleccionar una métrica de rendimiento - <span style=color:blue><b>performance metric</b></span> para evaluar la habilidad de un modelo, estableciendo un limite de base o un limite en el rendimiento con el que se puedan comparar todas las evaluaciones del modelo, y una técnica de remuestreo - <span style=color:blue><b>resampling technique</b></span> para dividir los datos en conjuntos de entrenamiento y prueba - <span style=color:blue><b>training and test</b></span> para simular cómo se utilizará el modelo final.\n",
    "\n",
    "Para estimaciones rápidas y de pruebas del rendimiento del modelo, o para un conjunto de datos muy grande, se puede realizar una sola <span style=color:blue><b>train-test split</b></span> de los datos. Es más común utilizar la validación cruzada de k-fold - <span style=color:blue><b>k-fold cross-validation</b></span> como técnica de remuestreo de datos - <span style=color:blue><b>resampling technique</b></span>, a menudo con repeticiones del proceso para mejorar la solidez del resultado.\n",
    "\n",
    "Este paso también implica tareas para aprovechar al máximo los modelos de buen rendimiento, como el ajuste de hiperparámetros - <span style=color:blue><b>hyperparameter tuning</b></span>. y los conjuntos de modelos - <span style=color:blue><b>ensembles of models</b></span>.\n",
    "\n",
    "## <b><u>Paso 4:</u></b> <span style=color:blue><b>Finalizar modelo.</b></span>\n",
    "\n",
    "Este paso tiene que ver con la selección y el uso de un modelo final.\n",
    "\n",
    "Una vez que se ha evaluado un conjunto de modelos, debemos elegir un modelo que represente la \"solución\" para el proyecto. Esto se denomina selección de modelo - <span style=color:blue><b>model selection</b></span> y puede implicar una evaluación adicional de los modelos candidatos en un conjunto de datos de validación en espera, o la selección a través de otros criterios específicos del proyecto, como la complejidad del modelo.\n",
    "\n",
    "También puede implicar resumir el desempeño del modelo de una manera estándar para todas las partes interesadas del proyecto, lo cual es un paso importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=color:darkgreen>¿Qué es la preparación de datos?</span>   \n",
    "\n",
    "En un proyecto de modelado predictivo, como <i>clasificación o la regresión</i>, los datos sin procesar normalmente no se pueden utilizar directamente.\n",
    "\n",
    "Esto se debe a razones como:\n",
    "\n",
    "- <span style=color:darkred>Los algoritmos de aprendizaje automático requieren que los datos sean números.</span>\n",
    "- <span style=color:darkred>Algunos algoritmos de aprendizaje automático imponen requisitos a los datos.</span>\n",
    "- <span style=color:darkred>Es posible que sea necesario corregir el ruido estadístico y los errores en los datos.</span>\n",
    "- <span style=color:darkred>Las relaciones no lineales complejas pueden extraerse de los datos.</span>\n",
    "\n",
    "Como tal, los datos sin procesar deben procesarse previamente antes de usarse para ajustar y evaluar un modelo de aprendizaje automático. Este paso en un proyecto de modelado predictivo se conoce como <span style=color:darkblue><b>\"preparación de datos - data pre-processing”, “feature engineering“</b></span>. Algunos de estos nombres pueden encajar mejor como subtareas para el proceso más amplio de preparación de datos.\n",
    "\n",
    "Podemos definir la preparación del dataset como la transformación de datos sin procesar en una forma más adecuada para el modelado.\n",
    "\n",
    "<span style=color:red>Esto es muy específico de de cada dataset, de los objetivos del proyecto y de los algoritmos que se utilizarán para modelar los datos.</span>\n",
    "\n",
    "Sin embargo, existen tareas comunes o estándar que podemos usar o explorar durante el proceso de preparación de datos  - <span style=color:darkred><b>data pre-processing</b></span> en nuestro proyecto de aprendizaje automático.\n",
    "\n",
    "Estas tareas incluyen:\n",
    "\n",
    "- <span style=color:blue> <b> Limpieza de datos - Data Cleaning: </b> </span> Identificación y corrección de errores o errores en los datos.\n",
    "- <span style=color:blue><b> Selección de Variables - Feature Selection:</b> </span> Identifica las variables de entrada que son más relevantes para la tarea.\n",
    "- <span style=color:blue><b>Transformación del dato - Data Transforms:</b> </span> Cambiar la escala o distribución de variables.\n",
    "- <span style=color:blue><b>Ingeniería de Variables - Feature Engineering:</b> </span> Derivación de nuevas variables a partir de los datos disponibles.\n",
    "- <span style=color:blue><b> Reducción de dimensionalidad - Dimensionality Reduction:</b> </span> Creación de proyecciones compactas de los datos.\n",
    "    \n",
    "Cada una de estas tareas es un campo de estudio completo con algoritmos especializados.\n",
    "\n",
    "La <span style=color:blue><b>preparación de datos - Data Preprocesing</b></span> no se realiza a ciegas.\n",
    "\n",
    "En algunos casos, las variables deben codificarse o transformarse antes de que podamos aplicar un algoritmo de aprendizaje automático, como convertir <b>cadenas - strings</b> en <b>números</b>. En otros casos, es menos claro, como escalar una variable puede ser útil o no para un algoritmo.\n",
    "\n",
    "La filosofía aplicada en la <span style=color:blue><b>Preparación de datos - Data Preprocesing</b></span> busca descubrir cómo <span style=color:blue><b>exponer mejor la estructura subyacente del problema a los algoritmos de aprendizaje</b></span>.\n",
    "\n",
    "<span style=color:darkred><b>No conocemos la estructura subyacente del problema</b></span>; si lo hiciéramos, no necesitaríamos un algoritmo de aprendizaje para descubrirlo y aprender a hacer predicciones hábiles. Por lo tanto, exponer la estructura subyacente desconocida del problema es un proceso de descubrimiento, junto con el descubrimiento de los algoritmos de aprendizaje de mejor o mejor desempeño para el proyecto.\n",
    "\n",
    "Sin embargo, a menudo no conocemos la mejor re-representación de los predictores para mejorar el rendimiento del modelo. En cambio, la reelaboración de predictores es más un arte, que requiere las herramientas y la experiencia adecuadas para encontrar mejores representaciones de predictores. Además, es posible que debamos buscar muchas representaciones de predictores alternativos para mejorar el rendimiento del modelo.\n",
    "\n",
    "- [Source : Feature engineering and feature selection](http://www.feat.engineering/).\n",
    "\n",
    "Puede ser más complicado de lo que parece a primera vista. Por ejemplo, diferentes variables de entrada pueden requerir diferentes métodos de preparación de datos. Además, diferentes variables o subconjuntos de variables de entrada pueden requerir diferentes secuencias de métodos de preparación de datos.\n",
    "\n",
    "Puede resultar abrumador, dada la gran cantidad de métodos, cada uno de los cuales puede tener su propia configuración y requisitos.   \n",
    "\n",
    "<span style=color:darkblue><b>Sin embargo, los pasos del proceso de aprendizaje automático antes y después de la preparación de datos pueden ayudar a informar qué técnicas considerar.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=color:darkblue>Que Técnicas de preparación de datos utilizar en nuestros datos?</span>\n",
    "\n",
    "¿Cómo sabemos qué técnicas de preparación de datos utilizar en nuestros datos?\n",
    "\n",
    "<i>\"Como ocurre con muchas preguntas de estadística, la respuesta a\" ¿qué métodos de ingeniería de Variables - Feature Engineering son los mejores? \" es que depende. Específicamente, depende del modelo que se utilice y de la verdadera relación con el resultado \".</i>\n",
    "\n",
    "Sinembargo, si observamos el proceso en la preparación del dato en el contexto de todo el proyecto, se vuelve más sencillo. Los pasos en un proyecto de modelado predictivo antes y después del paso de preparación del dato, nos informan de la preparación del dato que puede ser necesaria.\n",
    "\n",
    "El paso previo a la preparación de datos implica <span style=color:darkblue><b>definir el problema</b></span>.\n",
    "\n",
    "Como parte de la definición del problema, esto puede implicar muchas subtareas, como:\n",
    "\n",
    "- <span style=color:blue> <i>Adquirir datos del dominio del problema</i> </span>.\n",
    "- <span style=color:blue> <i>Discutir el proyecto con expertos en la materia</i> </span>.\n",
    "- <span style=color:blue> <i>Seleccionar las variables que se utilizarán como entradas y salidas para un modelo predictivo</i> </span>.\n",
    "- <span style=color:blue> <i>Revisar los datos que se han recopilado.</i> </span>\n",
    "- <span style=color:blue> <i>Resumir los datos recopilados mediante métodos estadísticos.</i> </span>\n",
    "- <span style=color:blue> <i>Visualice los datos recopilados utilizando gráficos y diagramas.</i> </span>\n",
    "\n",
    "La información conocida e extraida sobre los datos se puede utilizar para seleccionar y configurar métodos de preparación del dato.\n",
    "\n",
    "Por ejemplo, los gráficos de los datos pueden ayudar a identificar si una variable tiene valores atípicos. Esto puede ayudar en las operaciones de limpieza de datos. También puede proporcionar información sobre la distribución de probabilidad que subyace en los datos. Esto puede ayudar a determinar si las transformaciones de datos que cambian la distribución de probabilidad de una variable serían apropiadas.\n",
    "\n",
    "Se pueden utilizar métodos estadísticos, como la estadística descriptiva, para determinar si es posible que se requieran operaciones de escalado. Las pruebas de hipótesis estadísticas se pueden utilizar para determinar si una variable coincide con una distribución de probabilidad dada.\n",
    "\n",
    "Se pueden utilizar gráficas y estadísticas por pares - bivariates, para determinar si las variables están relacionadas y, de ser así, cuánto, proporcionando información sobre si una o más variables son redundantes o irrelevantes para la variable objetivo.\n",
    "\n",
    "Como tal, puede haber mucha interacción entre la definición del problema y la preparación de los datos.\n",
    "\n",
    "También puede haber una interacción entre el paso de preparación de datos y la evaluación de modelos.\n",
    "\n",
    "Por ejemplo, la elección de algoritmos puede imponer requisitos y expectativas sobre el tipo y la forma de las variables de entrada en los datos. Esto puede requerir que las variables tengan una distribución de probabilidad específica, la eliminación de variables de entrada correlacionadas y / o la eliminación de variables que no están fuertemente relacionadas con la variable objetivo.\n",
    "\n",
    "La elección de la métrica de rendimiento también puede requerir una preparación cuidadosa de la variable objetivo para cumplir con las expectativas, como modelos de regresión de puntuación basados en el error de predicción utilizando una unidad de medida específica, lo que requiere la inversión de cualquier transformación de escala aplicada a esa variable para el modelado.\n",
    "\n",
    "Estos ejemplos, entre otros muchos, destacan que, aunque la preparación de datos es un paso importante en un proyecto de modelado predictivo, no es un proceso independiente. Está fuertemente influenciado por las tareas realizadas tanto antes como después de la preparación de datos. Esto resalta la naturaleza altamente iterativa de cualquier proyecto de modelado predictivo.\n",
    "\n",
    "La evaluación del modelo puede incluir subtareas como:\n",
    "\n",
    "- <span style=color:blue>Seleccionar una métrica de rendimiento para evaluar la habilidad predictiva del modelo.</span>\n",
    "- <span style=color:blue>Seleccionar un procedimiento de evaluación del modelo.</span>\n",
    "- <span style=color:blue>Seleccionar algoritmos para evaluar.</span>\n",
    "- <span style=color:blue>Sintonizar hiperparámetros del algoritmo.</span>\n",
    "- <span style=color:blue>Combinar modelos predictivos en conjuntos - ensembles.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=color:darkblue>La importancía de Escalar el Dato - Data Scaling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de aprendizaje automático aprenden mapeando las variables de entrada-input a una variable de salida-output.   \n",
    "\n",
    "La escala y distribución de los datos extraídos del dominio pueden ser diferentes para cada variable.\n",
    "Las variables de entrada pueden tener diferentes unidades (ej. pies, kilómetros y horas) que, a su vez, puede\n",
    "significar que las variables tienen diferentes escalas.   \n",
    "\n",
    "Las diferencias en las escalas entre las variables de entrada pueden aumentar la dificultad del problema que se está modelando.   \n",
    "\n",
    "Un ejemplo de esto es esa gran entrada Los valores (por ejemplo, una extensión de cientos o miles de unidades) pueden dar como resultado un modelo que aprende grandes valores de <b>peso - weight</b>. Un modelo con valores de peso grandes suele ser inestable, lo que significa que puede sufrir de un rendimiento deficiente durante el aprendizaje y la sensibilidad a los valores de entrada, lo que resulta en un mayor error de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos algoritmos de aprendizaje automático funcionan mejor cuando se escalan las variables de entrada numéricas\n",
    "a un rango estándar. \n",
    "\n",
    "Las técnicas más populares para escalar datos numéricos <b><u>antes del modelado</u></b> son la <span style=color:darkred><b>Normalización</b></span> y <span style=color:darkred><b>Estandarización</b></span>.   \n",
    "\n",
    "## <span style=color:darkred><b>Normalizacion</b></span>\n",
    "\n",
    "- La <span style=color:darkred><b>Normalización</b></span> escala cada variable de entrada por separado al rango 0-1. <span style=color:darkred><b>Normalización</b></span> es un cambio de escala de los datos del rango original para que todos los valores estén dentro del nuevo rango de 0 y 1. La <span style=color:darkred><b>Normalización</b></span> requiere que seamos capaces de estimar con precisión los valores mínimos y máximos observables. Es posible que pueda estimar estos valores a partir de sus datos disponibles.   \n",
    "\n",
    "Podemos <span style=color:darkred><b>Normalizar</b></span> nuestro Dataset utilizado el Objecto de la libreria scikit-learn object <span style=color:blue><b>MinMaxScaler. </b></span>\n",
    "\n",
    "<span style=color:blue><b>sklearn.preprocessing.MinMaxScaler API.</b></span>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "Un valor se Normaliza de la siguiente manera :\n",
    "\n",
    "\\begin{align*}{y}\\hspace{2mm}=\\hspace{2mm}\\frac{{x} - min}{max - min}\\hspace{2mm}\\end{align*}\n",
    "<p>&nbsp;</p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=color:darkred><b>Estandarización</b></span>\n",
    "\n",
    "<span style=color:darkred><b>Estandarizar - Standardizing</b></span> un conjunto de datos implica <u>reescalar la <b>distribución de valores</b></u> para que la <b>media</b> de los valores observados sea <b>0</b> y la <b>desviación estándar</b> sea <b>1</b>.\n",
    "\n",
    "<span style=color:darkred><b>La Estandarización</b></span> escala cada variable de entrada por separado restando la media (llamado centrado - centering) y dividiendo por la desviación estándar para cambiar la distribución, Y de esta manera otener una media de cero y una desviación estándar de uno.\n",
    "\n",
    "La <span style=color:darkred><b>estandarización</b></span> supone que sus observaciones se <b>ajustan - fit a una <u>distribución gaussiana</u> (curva de campana)</b> con una media y una desviación estándar de buen comportamiento.\n",
    "\n",
    "Aún podemos <span style=color:darkred><b>estandarizar</b> el dataset si no se cumple esta expectativa, pero es posible que no obtengamos resultados confiables.\n",
    "\n",
    "Un valor se Estandariza de la siguiente manera :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:48:00.807518Z",
     "start_time": "2021-05-06T16:48:00.800537Z"
    }
   },
   "source": [
    "\\begin{align*}{y}\\hspace{2mm}=\\hspace{2mm}\\frac{{x} - mean}{Standard\\hspace{2mm}Deviation}\\hspace{2mm}\\end{align*}   \n",
    "\n",
    "<p>&nbsp;</p>\n",
    "Las estimaciones de la desviación estándar y media de un conjunto de datos pueden ser más robustas para los datos nuevos que el mínimo y el máximo, utilizados en la <b><u>Normalización</u></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos <span style=color:darkred><b>Estandarizar</b></span> nuestro Dataset utilizado el Objecto de la libreria scikit-learn object <span style=color:blue><b>StandardScaler.</b></span>  \n",
    "\n",
    "<span style=color:blue><b>sklearn.preprocessing.StandardScaler API.</b></span>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta diferencia en la escala de las variables de entrada no afecta a todos los algoritmos de aprendizaje automático.   \n",
    "\n",
    "Algoritmos que se <b><u>ajustan - fit</u></b> a un modelo que utiliza una suma ponderada de variables de entrada se ven afectados, como por ejemplo regresión lineal, regresión logística y redes neuronales artificiales (aprendizaje profundo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pero, ¿cuál es mejor?   \n",
    "\n",
    "Se desconoce. \n",
    "\n",
    "Evalúamos modelos con datos preparados en cada transformación y usamos la transformación o combinación de transformaciones que resulten en el mejor rendimiento del conjunto de datos en nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuándo normalizar y estandarizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La <span style=color:darkred><b>estandarización</b></span> es una técnica de escalado que asume que sus datos se ajustan a una <span style=color:darkred><b><u>distribución normal.</u></b></span>\n",
    "\n",
    "Si un atributo - variale del dataset dado es normal o cercano a lo normal, este es probablemente el método de <span style=color:darkred><b>escalado</b></span> a utilizar.\n",
    "\n",
    "Es una buena práctica explorar las <b>estadísticas de resumen - <u>summary statistics</u></b> utilizadas en el proceso de <span style=color:darkred><b>estandarización</b></span>, de modo que pueda aplicarlas cuando estandarice datos en el futuro que quizás necesitemos usar con nuestro modelo.\n",
    "\n",
    "La <span style=color:darkred><b>normalización</b></span> es una técnica de escalado que no asume ninguna <span style=color:darkred><b><u>distribución específica</u></b>.\n",
    "\n",
    "Si los datos no se distribuyen normalmente, consideraremos normalizarlos antes de aplicar su algoritmo de aprendizaje automático.\n",
    "\n",
    "Es una buena práctica registrar los valores mínimos y máximos para cada columna utilizada en el proceso de normalización, en caso de que necesite normalizar nuevos datos en el futuro para usarlos en nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ¿Debería estandarizar y luego normalizar?\n",
    "\n",
    "La <span style=color:darkred><b>estandarización</b></span> puede dar valores tanto positivos como negativos centrados alrededor de cero. Puede ser conveniente normalizar los datos después de que se hayan estandarizado. Esta podría ser una buena idea si tiene una combinación de variables estandarizadas y normalizadas y desea que todas las variables de entrada tengan los mismos valores mínimos y máximos que la entrada para un algoritmo dado, como un algoritmo que calcula medidas de distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:36:06.668219Z",
     "start_time": "2021-05-06T15:36:06.650269Z"
    }
   },
   "source": [
    "## ¿Cómo manejo los valores fuera de límites? How Do I Handle Out-of-Bounds Values?     \n",
    "\n",
    "Podemos <span style=color:darkred><b>Normalizar</b></span> lo datos calculando el mínimo y el máximo en los <b>datos de entrenamiento - <u>Train dataset</u></b>.  \n",
    "\n",
    "Más adelante, es posible que tenga nuevos datos con valores más pequeños o más grandes que el mínimo o el máximo respectivamente. Un enfoque simple para manejar esto puede ser verificar dichos valores fuera del límite y cambiar sus valores al mínimo o máximo conocido antes de escalar. Alternativamente, es posible que desee estimar los valores mínimos y máximos utilizados en la normalización de forma manual en función del conocimiento del dominio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T10:12:50.115550Z",
     "start_time": "2021-05-10T10:12:50.106575Z"
    }
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "La idea de las transformaciones de datos es exponer mejor la estructura de nuestro problema en sus datos al algoritmo de aprendizaje.\n",
    "\n",
    "Puede que no esté claro qué transformaciones se requieren por adelantado. Una combinación de prueba y error y análisis de datos exploratorios (gráficos y estadísticas) puede ayudar a descubrir qué puede funcionar.\n",
    "\n",
    "A continuación, se muestran algunas transformaciones adicionales que puede considerar investigar e implementar:\n",
    "\n",
    "- Normalización que permite un rango configurable, como -1 a 1 y más.\n",
    "- Estandarización que permite un margen configurable, como 1, 2 o más desviaciones estándar de la media.\n",
    "- Transformaciones exponenciales como logaritmo, raíz cuadrada y exponentes.\n",
    "- Transformaciones de energía como box-cox para corregir el sesgo en los datos distribuidos normalmente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
